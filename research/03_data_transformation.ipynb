{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875de2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\fiscarelli\\\\Desktop\\\\Progetti\\\\Manpower IT\\\\Auto-Match\\\\Candidates-to-Jobs-Auto-Match-Cortex-AI'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"snowflake\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"snowflake.connector\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"snowflake.snowpark\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "%pwd\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# Add the absolute path to src/ so Python can find automatch\n",
    "src_path = os.path.abspath(\"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c1705f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\fiscarelli\\\\Desktop\\\\Progetti\\\\Manpower IT\\\\Auto-Match\\\\Candidates-to-Jobs-Auto-Match-Cortex-AI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9155a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://login.microsoftonline.com/e2ba81b8-03fe-407c-96a1-f4bc0f512e7d/saml2?SAMLRequest=nZJbb%2BIwEIX%2FSuR9TuIYuoAFVEChi9QLKmml7ZtJJmDVsVOP09D%2B%2BjpcpO5D%2B7Bvln1mvuM5M7zclyp4A4vS6BFJIkoC0JnJpd6OyGO6CPskQCd0LpTRMCLvgORyPERRqopParfTD%2FBaA7rAN9LI24cRqa3mRqBErkUJyF3G15PbG84iygUiWOdx5FSSo%2FSsnXMVj%2BOmaaKmExm7jRmlNKaD2KtayS%2FyBVH9zKiscSYz6lyy93%2F6BpHEtNsivMITVqfCqdTHEfxE2RxFyP%2Bk6Spc3a9TEkzOv5sZjXUJdg32TWbw%2BHBzNIDewXQ96FLWjxo%2FtxBqayqIxEdtIUJtmkKJF8hMWdXOd4%2F8KS4gj5XZSj%2Bz5dWIVC8yVx%2BL%2FfU9lrfL17mbd%2F66efp8lz5Ni0JukJYpXO96YjZZsO48I8HTOWHWJrxErGGp21ydv6LsIkxoSHspHXBGeacTsR57JsGV9ye1cIfKs%2FmDj6iUmTVoCme0khoOLoFtRD%2FZ9EPaKSDs0l4WDn6LJCy6m4wWFwmDXh636TFy3CB%2BMGLH%2FzuXYfy1y2kp73xOy6uVUTJ7DxbGlsJ9H2MSJYcbmYfFQcqhFFJN8twCoo9TKdPMLAjnd9%2FZGkg8PlL%2F3f7xJw%3D%3D&RelayState=ver%3A1-hint%3A126482531967198-ETMsDgAAAZm9%2BPP4ABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEDjO20RiyPfWAM8SeK8qA4oAAACg%2F9DWqpMwD7GFdOS5v2Su7x1u1rgsjpSejCErrv9fvGar%2F98R3Y%2FWZ2a5wFgAP%2F7hI7160NCa4XQf1hx84aWnGCYfuh379mRjq%2F8CUpLDUoY391np2NJci9vN6QGlr1SnOgOqIKIt5L4TzKD34x8itu%2BjosxKZCgZJAhLidFQUwQZpxaf1JYTOeMMy6K0r%2B66dLZKh0qhpEz6fNZsUiUw2wAUPFTPMyf3zDeD8WOVK9ejknFLbB4%3D to authenticate...\n"
     ]
    }
   ],
   "source": [
    "from autoMatch.utils.snowflake_utils import get_snowpark_session\n",
    "session = get_snowpark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc40000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: str\n",
    "    database: str\n",
    "    schema: str\n",
    "    input_table: str\n",
    "    input_table_cleaned: str\n",
    "    output_table: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdecf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoMatch.constants import *\n",
    "from autoMatch.utils.common import read_yaml, create_directories\n",
    "from autoMatch import logger\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            database=config.database,\n",
    "            schema=config.schema,\n",
    "            input_table=config.input_table,\n",
    "            input_table_cleaned=config.input_table_cleaned,\n",
    "            output_table = config.output_table,\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af745682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col, trim, lower, length, expr\n",
    "from snowflake.snowpark.types import StringType\n",
    "\n",
    "from snowflake.snowpark.functions import udf\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def clean_description_old(self, session):\n",
    "        \"\"\"\n",
    "        Reads input table\n",
    "        Cleans description column:\n",
    "            - removes rows with empty description\n",
    "            - replaces multiple consecutive whitespaces with a single whitespace (preserves newlines)\n",
    "            - removes all html tags\n",
    "            - lowercases all text\n",
    "        Performs Named Entity Recognition\n",
    "        Function returns Snowflake dataframe\n",
    "        \"\"\"\n",
    "        database = self.config.database\n",
    "        schema = self.config.schema\n",
    "        input_table = self.config.input_table\n",
    "        input_table_cleaned = self.config.input_table_cleaned\n",
    "\n",
    "        df = session.table(f\"{database}.{schema}.{input_table}\").limit(100)\n",
    "        df = df.filter((col(\"description\").is_not_null()) & (trim(col(\"description\")) != \"\"))\n",
    "\n",
    "\n",
    "        def normalize_whitespace(text: str) -> str:\n",
    "            import re\n",
    "            return re.sub(r'[ \\t]+', ' ', text).strip()\n",
    "\n",
    "        normalize_whitespace_udf = udf(\n",
    "            normalize_whitespace, \n",
    "            return_type=StringType(), \n",
    "            input_types=[StringType()]\n",
    "            )\n",
    "\n",
    "        df = df.with_column(\"description\", normalize_whitespace_udf(df[\"description\"]))\n",
    "\n",
    "\n",
    "        def clean_html(text: str) -> str:\n",
    "            from bs4 import BeautifulSoup\n",
    "            if not text:\n",
    "                return \"\"\n",
    "            return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "        clean_html_udf = udf(\n",
    "            clean_html,\n",
    "            return_type=StringType(),\n",
    "            input_types=[StringType()],\n",
    "            packages=[\"beautifulsoup4\"]\n",
    "            )\n",
    "\n",
    "        df = df.with_column(\"description\", clean_html_udf(df[\"description\"]))\n",
    "\n",
    "        df = df.with_column(\"description\", lower(df[\"description\"]))\n",
    "\n",
    "        df = df.filter((col(\"description\").is_not_null()) & \n",
    "                       (trim(col(\"description\")) != \"\") &\n",
    "                       (length(trim(col(\"description\"))) > 5) &\n",
    "                       (~col(\"description\").like(\"%None%\")) &\n",
    "                       (~col(\"description\").like(\"%null%\"))\n",
    "                       )\n",
    "\n",
    "        df = df.with_column(\"description\", col(\"description\").cast(\"STRING\"))\n",
    "        \n",
    "        def remove_special_chars(text: str) -> str:\n",
    "            import re\n",
    "            if not text:\n",
    "                return \"\"\n",
    "            return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "        remove_special_chars_udf = udf(\n",
    "            remove_special_chars,\n",
    "            return_type=StringType(),\n",
    "            input_types=[StringType()]\n",
    "        )\n",
    "        df = df.with_column(\"description\", remove_special_chars_udf(df[\"description\"]))\n",
    "\n",
    "        df.write.save_as_table(\n",
    "            input_table_cleaned,\n",
    "            mode=\"overwrite\",\n",
    "        )\n",
    "        logger.info(f\"Table {input_table} successfully cleaned\")\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT\n",
    "                *,\n",
    "                SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                    'claude-4-sonnet',\n",
    "                    CONCAT(\n",
    "                        'Estrai dal seguente testo i campi: age (numero), date_of_birth (YYYY-MM-DD), location (stringa), zip_code (numero), last_job, second_last_job, third_last_job, skills (stringa). ',\n",
    "                        'Rispondi in formato JSON, senza testo extra, attieniti a questo esempio: {{\"age\": 30, \"date_of_birth\": \"1993-05-12\", \"location\": \"Milano\", \"zip_code\": 20100, \"last_job\": \"Data Engineer\", \"second_last_job\": \"Developer\", \"third_last_job\": \"Intern\", \"skills\": \"Python, SQL\"}}. ',\n",
    "                        'Testo: ', description\n",
    "                    )\n",
    "                ) AS parsed_json\n",
    "            FROM {database}.{schema}.{input_table_cleaned}\n",
    "\n",
    "            \"\"\"\n",
    "         \n",
    "        import json\n",
    "\n",
    "        response_format = {\n",
    "            \"età\": \"Qual è l età del candidato? (numero)\",\n",
    "            \"data_di_nascita\": \"Qual e la data di nascita del candidato? Restituisci solo uno in formato stringa ANNO-MESE-GIORNO\",\n",
    "            \"località\": \"Qual è la località del candidato? Restituisci solo uno in formato stringa\",\n",
    "            \"cap\": \"Qual è il codice postale del candidato? Restituisci solo uno in formato stringa\",\n",
    "            \"ultimo_lavoro\": \"Qual è l ultimo lavoro svolto dal candidato? Restituisci solo uno in formato stringa, il tipo di lavoro, non l azienda o il datore di lavoro\",\n",
    "            \"penultimo_lavoro\": \"Qual è il penultimo lavoro svolto dal candidato? Restituisci solo uno in formato stringa, il tipo di lavoro, non l azienda o il datore di lavoro\",\n",
    "            \"terzultimo_lavoro\": \"Qual è il terzultimo lavoro svolto dal candidato? Restituisci solo uno in formato stringa, il tipo di lavoro, non l azienda o il datore di lavoro\",\n",
    "            \"competenze\": \"Qual è l elenco delle competenze del candidato? (stringa di competenze separate da virgola)\"\n",
    "        }\n",
    "\n",
    "        response_json = json.dumps(response_format)\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT \n",
    "                *, \n",
    "                AI_EXTRACT(\n",
    "                text => TO_VARCHAR(description),\n",
    "                responseFormat => PARSE_JSON('{response_json}')\n",
    "                ) AS ner_json\n",
    "                FROM {database}.{schema}.{input_table_cleaned}\n",
    "        \"\"\"\n",
    "        \n",
    "        qq = f\"\"\"\n",
    "                AI_EXTRACT(\n",
    "                text => description,\n",
    "                responseFormat => PARSE_JSON('{response_json}')\n",
    "                )\n",
    "        \"\"\"\n",
    "        qq2 = \"\"\" \n",
    "                SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                    'claude-4-sonnet',\n",
    "                    CONCAT(\n",
    "                        'Estrai dal seguente testo i campi: age (numero), date_of_birth (YYYY-MM-DD), location (stringa), zip_code (numero), last_job, second_last_job, third_last_job, skills (stringa). ',\n",
    "                        'Rispondi in formato JSON, senza testo extra, attieniti a questo esempio: {{\"age\": 30, \"date_of_birth\": \"1993-05-12\", \"location\": \"Milano\", \"zip_code\": 20100, \"last_job\": \"Data Engineer\", \"second_last_job\": \"Developer\", \"third_last_job\": \"Intern\", \"skills\": \"Python, SQL\"}}. ',\n",
    "                        'Testo: ', description\n",
    "                    )\n",
    "                )\n",
    "                \"\"\"\n",
    "\n",
    "        '''\n",
    "        df = session.sql(f\"SELECT * FROM {database}.{schema}.{input_table_cleaned}\")\n",
    "        descriptions = df.select(col(\"description\").alias(\"description\")).collect()\n",
    "        rcount = ecount = 0\n",
    "        for row in descriptions:\n",
    "            desc = row[0]  # or row[\"description\"] if aliased\n",
    "            try:\n",
    "                single_df = df.filter(col(\"description\") == desc)\n",
    "                single_df = single_df.with_column(\"ner_json\", expr(qq))\n",
    "                single_df.select(\"ner_json\").show()\n",
    "                rcount += 1\n",
    "            except Exception as e:\n",
    "                ecount += 1\n",
    "                print(f\"Errore {ecount} su: {desc}\")\n",
    "        print(f\"Numero totale di errori: {ecount}\")\n",
    "        '''\n",
    "\n",
    "        df_with_ner = session.sql(query).collect()\n",
    "        df_with_ner = df_with_ner.filter(df_with_ner[\"ner_json\"].is_not_null())\n",
    "        df_with_ner = df_with_ner.filter(\n",
    "            (col(\"ner_json\")[\"response\"].is_not_null()) &\n",
    "            (trim(col(\"ner_json\")[\"response\"]) != \"\")\n",
    "            )\n",
    "\n",
    "        df_with_ner = df_with_ner.with_columns(\n",
    "            [\"age\", \"date_of_birth\", \"location\", \"zip_code\", \"last_job\", \"second_last_job\", \"third_last_job\", \"skills\"],\n",
    "            [\n",
    "                col(\"ner_json\")[\"response\"][\"età\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"response\"][\"data_di_nascita\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"response\"][\"località\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"response\"][\"cap\"].cast(\"STRING\"), \n",
    "                col(\"ner_json\")[\"response\"][\"ultimo_lavoro\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"response\"][\"penultimo_lavoro\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"response\"][\"terzultimo_lavoro\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"response\"][\"competenze\"].cast(\"STRING\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        df_with_ner = df_with_ner.drop(\"ner_json\")\n",
    "\n",
    "        #print(df_with_ner.show(100))\n",
    "        logger.info(f\"NER on {input_table} table successful\")\n",
    "\n",
    "\n",
    "        return df_with_ner\n",
    "\n",
    "\n",
    "    def clean_description(self, session):\n",
    "        \"\"\"\n",
    "        Reads input table\n",
    "        Cleans description column:\n",
    "            - removes rows with empty description\n",
    "            - replaces multiple consecutive whitespaces with a single whitespace (preserves newlines)\n",
    "            - removes all html tags\n",
    "            - lowercases all text\n",
    "        Function returns Snowflake dataframe\n",
    "        \"\"\"\n",
    "        database = self.config.database\n",
    "        schema = self.config.schema\n",
    "        input_table = self.config.input_table\n",
    "        input_table_cleaned = self.config.input_table_cleaned\n",
    "\n",
    "        df = session.table(f\"{database}.{schema}.{input_table}\").limit(100)\n",
    "        df = df.filter((col(\"description\").is_not_null()) & (trim(col(\"description\")) != \"\"))\n",
    "\n",
    "        def build_normalize_whitespace_udf():\n",
    "            def normalize(text: str) -> str:\n",
    "                import re\n",
    "                if text is None:\n",
    "                    return ''\n",
    "                return re.sub(r'[ \\t]+', ' ', text).strip()\n",
    "\n",
    "            return udf(normalize, return_type=StringType(), input_types=[StringType()])\n",
    "        normalize_udf = build_normalize_whitespace_udf()\n",
    "        df = df.with_column(\"description\", normalize_udf(df[\"description\"]))\n",
    "        \n",
    "\n",
    "        def build_clean_html_udf():\n",
    "            from bs4 import BeautifulSoup\n",
    "            def clean_html(text: str) -> str:\n",
    "                if not text:\n",
    "                    return \"\"\n",
    "                return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "            return udf(\n",
    "                clean_html,\n",
    "                return_type=StringType(),\n",
    "                input_types=[StringType()],\n",
    "                packages=[\"beautifulsoup4\"]\n",
    "            )\n",
    "\n",
    "        clean_html_udf = build_clean_html_udf()\n",
    "        df = df.with_column(\"description\", clean_html_udf(df[\"description\"]))\n",
    "\n",
    "        df = df.with_column(\"description\", lower(df[\"description\"]))\n",
    "\n",
    "        df = df.filter((col(\"description\").is_not_null()) & \n",
    "                       (trim(col(\"description\")) != \"\") &\n",
    "                       (length(trim(col(\"description\"))) > 5) &\n",
    "                       (~col(\"description\").like(\"%None%\")) &\n",
    "                       (~col(\"description\").like(\"%null%\"))\n",
    "                       )\n",
    "\n",
    "        df = df.with_column(\"description\", col(\"description\").cast(\"STRING\"))\n",
    "\n",
    "        def build_remove_special_chars_udf():\n",
    "            import re\n",
    "            def remove_special_chars(text: str) -> str:\n",
    "                if not text:\n",
    "                    return \"\"\n",
    "                return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "            return udf(\n",
    "                remove_special_chars,\n",
    "                return_type=StringType(),\n",
    "                input_types=[StringType()]\n",
    "            )\n",
    "        remove_special_chars_udf = build_remove_special_chars_udf()\n",
    "        df = df.with_column(\"description\", remove_special_chars_udf(df[\"description\"]))\n",
    "\n",
    "\n",
    "        df.write.save_as_table(\n",
    "            input_table_cleaned,\n",
    "            mode=\"overwrite\",\n",
    "        )\n",
    "        logger.info(f\"Table {input_table} successfully cleaned\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def apply_ner_cortexai(self, session):\n",
    "        \"\"\"\n",
    "        Reads input table\n",
    "\n",
    "        Performs Named Entity Recognition\n",
    "        Function returns Snowflake dataframe\n",
    "        \"\"\"\n",
    "\n",
    "        from snowflake.snowpark.functions import parse_json\n",
    "\n",
    "        database = self.config.database\n",
    "        schema = self.config.schema\n",
    "        input_table_cleaned = self.config.input_table_cleaned\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT\n",
    "                *,\n",
    "                SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                    'claude-4-sonnet',\n",
    "                    CONCAT(\n",
    "                        'Estrai dal seguente testo i campi: age (numero), date_of_birth (YYYY-MM-DD), location (stringa), zip_code (numero), last_job, second_last_job, third_last_job, skills (stringa). ',\n",
    "                        'Rispondi in formato JSON, senza testo extra, attieniti a questo esempio: {{\"age\": 30, \"date_of_birth\": \"1993-05-12\", \"location\": \"Milano\", \"zip_code\": 20100, \"last_job\": \"Data Engineer\", \"second_last_job\": \"Developer\", \"third_last_job\": \"Intern\", \"skills\": \"Python, SQL\"}}. ',\n",
    "                        'Testo: ', description\n",
    "                    )\n",
    "                ) AS ner_json\n",
    "            FROM {database}.{schema}.{input_table_cleaned}\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "        df = session.sql(query)\n",
    "\n",
    "        def build_clean_parsing_udf():\n",
    "            def clean(x: str) -> str:\n",
    "                if x is None:\n",
    "                    return ''\n",
    "                x = x.lower().lstrip()\n",
    "                if x.startswith(\"```json\"):\n",
    "                    x = x[8:].lstrip()\n",
    "                x = x.replace('\\n', ' ').replace('\\t', ' ').replace('\\\\', '').strip()\n",
    "                x = ' '.join(x.split())\n",
    "                if x.endswith(\"```\"):\n",
    "                    x = x[:-3].rstrip()\n",
    "                if x.endswith(\"'\") or x.endswith('\"'):\n",
    "                    x = x[:-1].rstrip()\n",
    "                return x\n",
    "\n",
    "            return udf(clean, return_type=StringType(), input_types=[StringType()])\n",
    "        clean_udf = build_clean_parsing_udf()\n",
    "\n",
    "        df = df.with_column(\"ner_json\", clean_udf(df[\"ner_json\"]))\n",
    "\n",
    "        def build_is_valid_json_udf():\n",
    "            import json\n",
    "            def is_valid(text: str) -> bool:\n",
    "                if not text:\n",
    "                    return False\n",
    "                try:\n",
    "                    json.loads(text)\n",
    "                    return True\n",
    "                except Exception:\n",
    "                    return False\n",
    "\n",
    "            return udf(is_valid, return_type=BooleanType(), input_types=[StringType()])\n",
    "        is_valid_json_udf = build_is_valid_json_udf()\n",
    "        df = df.with_column(\"is_valid_json\", is_valid_json_udf(df[\"ner_json\"]))\n",
    "        df = df.filter(col(\"is_valid_json\") == True)\n",
    "        df = df.drop(\"is_valid_json\")\n",
    "\n",
    "        df = df.with_column(\"ner_json\", parse_json(col(\"ner_json\")))\n",
    "\n",
    "        df = df.filter(df[\"ner_json\"].is_not_null())\n",
    "\n",
    "        df = df.with_columns(\n",
    "            [\"age\", \"date_of_birth\", \"location\", \"zip_code\", \"last_job\", \"second_last_job\", \"third_last_job\", \"skills\"],\n",
    "            [\n",
    "                col(\"ner_json\")[\"age\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"data_of_birth\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"location\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"zip_code\"].cast(\"STRING\"), \n",
    "                col(\"ner_json\")[\"last_job\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"second_last_job\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"third_last_job\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"skills\"].cast(\"STRING\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        df = df.drop(\"ner_json\")\n",
    "\n",
    "        logger.info(f\"NER on {input_table_cleaned} table successful\")\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    "    def write_table(self, session, df):\n",
    "        \"\"\"\n",
    "        Writes input table\n",
    "        Function returns nothing\n",
    "        \"\"\"\n",
    "        output_table = self.config.output_table\n",
    "\n",
    "        df.write.save_as_table(output_table, mode=\"overwrite\")\n",
    "        logger.info(f\"Table {output_table} successfully written\")\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4352f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-07 12:42:13,823: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-10-07 12:42:13,826: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-10-07 12:42:13,830: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-10-07 12:42:13,834: INFO: common: created directory at: artifacts]\n",
      "[2025-10-07 12:42:13,836: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-10-07 12:42:23,977: INFO: 1697729232: Table MPG_IT_AUTOMATCH_CANDIDATE successfully cleaned]\n",
      "[2025-10-07 12:42:25,080: INFO: 1697729232: NER on MPG_IT_AUTOMATCH_CANDIDATE_CLEANED table successful]\n",
      "[2025-10-07 12:42:40,524: INFO: 1697729232: Table MPG_IT_AUTOMATCH_CANDIDATE_FEATURES successfully written]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.clean_description(session)\n",
    "    df = data_transformation.apply_ner_cortexai(session)\n",
    "    data_transformation.write_table(session, df)\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b1870ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE_a</th>\n",
       "      <th>AGE_b</th>\n",
       "      <th>CANDIDATEID</th>\n",
       "      <th>DATE_ADDED</th>\n",
       "      <th>DATE_OF_BIRTH_a</th>\n",
       "      <th>DATE_OF_BIRTH_b</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>LAST_JOB_a</th>\n",
       "      <th>LAST_JOB_b</th>\n",
       "      <th>LOCATION_a</th>\n",
       "      <th>LOCATION_b</th>\n",
       "      <th>SECOND_LAST_JOB_a</th>\n",
       "      <th>SECOND_LAST_JOB_b</th>\n",
       "      <th>SKILLS_a</th>\n",
       "      <th>SKILLS_b</th>\n",
       "      <th>THIRD_LAST_JOB_a</th>\n",
       "      <th>THIRD_LAST_JOB_b</th>\n",
       "      <th>ZIP_CODE_a</th>\n",
       "      <th>ZIP_CODE_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5537727</td>\n",
       "      <td>2025-07-10 09:55:23.473</td>\n",
       "      <td>None</td>\n",
       "      <td>1966-08-24</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nernesta  \\nseghetti  \\nistruzione ...</td>\n",
       "      <td>operatore pulizie uffici</td>\n",
       "      <td>operatore pulizie uffici</td>\n",
       "      <td>bracciano</td>\n",
       "      <td>bracciano</td>\n",
       "      <td>assistente educativa culturale</td>\n",
       "      <td>assistente educativa culturale aec/oepa</td>\n",
       "      <td>capacità organizzative e gestionali, leadershi...</td>\n",
       "      <td>capacità organizzative e gestionali, leadershi...</td>\n",
       "      <td>receptionist front desk</td>\n",
       "      <td>receptionist front desk</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5539300</td>\n",
       "      <td>2025-07-11 07:48:14.140</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nmarco broccio  \\nitaly  available ...</td>\n",
       "      <td>transaction monitoring analyst</td>\n",
       "      <td>transaction monitoring analyst - freelance</td>\n",
       "      <td>italy</td>\n",
       "      <td>italy</td>\n",
       "      <td>market risk and behavioural analyst</td>\n",
       "      <td>market risk and behavioural analyst - freelance</td>\n",
       "      <td>investigation and analysis, screening and tran...</td>\n",
       "      <td>investigation and analysis, screening and tran...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5525349</td>\n",
       "      <td>2025-07-03 04:31:18.100</td>\n",
       "      <td>None</td>\n",
       "      <td>1980-05-18</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\ncurriculum vitae  \\ndati personali...</td>\n",
       "      <td>socio in azienda global srl</td>\n",
       "      <td>socio in azienda global srl pulimentatura metalli</td>\n",
       "      <td>san giovanni valdarno</td>\n",
       "      <td>san giovanni valdarno (ar)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>gestione amministrazione, vendite, back office...</td>\n",
       "      <td>gestione amministrazione, ufficio vendite, bac...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5547420</td>\n",
       "      <td>2025-07-16 09:16:40.633</td>\n",
       "      <td>None</td>\n",
       "      <td>1993-04-05</td>\n",
       "      <td>\\n simone facchini\\n\\n 63072 via borgo garibal...</td>\n",
       "      <td>programmatore cad/cam programmatore cnc</td>\n",
       "      <td>programmatore cad/cam, programmatore cnc</td>\n",
       "      <td>castignano</td>\n",
       "      <td>castignano</td>\n",
       "      <td>programmatore cad/cam programmatore cnc</td>\n",
       "      <td>programmatore cad/cam, programmatore cnc</td>\n",
       "      <td>programmazione cad/cam, cnc, fanuc, selca, hei...</td>\n",
       "      <td>programmazione fanuc, selca, heidenhain, progr...</td>\n",
       "      <td>agente assicurativo</td>\n",
       "      <td>agente assicurativo</td>\n",
       "      <td>63072</td>\n",
       "      <td>63072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5546372</td>\n",
       "      <td>2025-07-16 03:56:41.203</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-08-16</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nbruno gabriele cristiano  \\nnazion...</td>\n",
       "      <td>stagista</td>\n",
       "      <td>stagista fc impianti</td>\n",
       "      <td>vedano</td>\n",
       "      <td>vedano, italia</td>\n",
       "      <td>stagista</td>\n",
       "      <td>stagista fc impianti</td>\n",
       "      <td>infilaggio cavi, cablaggio, posa tubi, install...</td>\n",
       "      <td>installazione elettrica, cablaggio, posa tubi,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5532601</td>\n",
       "      <td>2025-07-08 05:06:07.990</td>\n",
       "      <td>None</td>\n",
       "      <td>1994-08-05</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nilaria abate  \\nnazionalit italian...</td>\n",
       "      <td>ispettore ambientale</td>\n",
       "      <td>ispettore ambientale</td>\n",
       "      <td>grosseto</td>\n",
       "      <td>grosseto</td>\n",
       "      <td>barista</td>\n",
       "      <td>barista</td>\n",
       "      <td>elaborazione delle informazioni, pensare in mo...</td>\n",
       "      <td>elaborazione delle informazioni, pensare in mo...</td>\n",
       "      <td>babysitter</td>\n",
       "      <td>babysitter</td>\n",
       "      <td>58100</td>\n",
       "      <td>58100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>53</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5568356</td>\n",
       "      <td>2025-07-30 12:48:18.103</td>\n",
       "      <td>None</td>\n",
       "      <td>1971-01-31</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nmaria angela cirasola  \\nnazionali...</td>\n",
       "      <td>assistente familiare</td>\n",
       "      <td>assistente familiare</td>\n",
       "      <td>bolano sp</td>\n",
       "      <td>bolano (sp)</td>\n",
       "      <td>cameriera e lavapiatti</td>\n",
       "      <td>cameriera e lavapiatti</td>\n",
       "      <td>assistenza personale, servizio tavoli, pulizie...</td>\n",
       "      <td>assistenza personale, somministrazione terapie...</td>\n",
       "      <td>addetta alle pulizie</td>\n",
       "      <td>addetta alle pulizie</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5561500</td>\n",
       "      <td>2025-07-25 08:37:11.100</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-07-20</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\ncurriculum vitae europass  \\ncurri...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>siena</td>\n",
       "      <td>siena</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>elettronica, elettrotecnica, automazione</td>\n",
       "      <td>elettronica e elettrotecnica, automazione</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>53100</td>\n",
       "      <td>53100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5558157</td>\n",
       "      <td>2025-07-23 10:16:22.037</td>\n",
       "      <td>None</td>\n",
       "      <td>1993-01-14</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nnina nicoleta movila  \\ndata di na...</td>\n",
       "      <td>badante</td>\n",
       "      <td>badante</td>\n",
       "      <td>roma</td>\n",
       "      <td>roma</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>social, windows, gestione posta elettronica, u...</td>\n",
       "      <td>social, windows, gestione posta elettronica, u...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>166</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5567471</td>\n",
       "      <td>2025-07-30 06:25:39.503</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\nflavia pralea  legal counsel  \\nfl...</td>\n",
       "      <td>corporate legal counsel</td>\n",
       "      <td>corporate legal counsel</td>\n",
       "      <td>vicenza, italy</td>\n",
       "      <td>vicenza</td>\n",
       "      <td>legal specialist</td>\n",
       "      <td>legal specialist</td>\n",
       "      <td>corporate legal advisory, contract negotiation...</td>\n",
       "      <td>corporate legal advisory, contract negotiation...</td>\n",
       "      <td>attorney</td>\n",
       "      <td>attorney</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE_a  AGE_b CANDIDATEID              DATE_ADDED DATE_OF_BIRTH_a  \\\n",
       "0     58   58.0     5537727 2025-07-10 09:55:23.473            None   \n",
       "1   None    NaN     5539300 2025-07-11 07:48:14.140            None   \n",
       "2     44   44.0     5525349 2025-07-03 04:31:18.100            None   \n",
       "3     30   31.0     5547420 2025-07-16 09:16:40.633            None   \n",
       "4     16   16.0     5546372 2025-07-16 03:56:41.203            None   \n",
       "..   ...    ...         ...                     ...             ...   \n",
       "88    30   30.0     5532601 2025-07-08 05:06:07.990            None   \n",
       "89    53   53.0     5568356 2025-07-30 12:48:18.103            None   \n",
       "90    18   18.0     5561500 2025-07-25 08:37:11.100            None   \n",
       "91    31   31.0     5558157 2025-07-23 10:16:22.037            None   \n",
       "92  None    NaN     5567471 2025-07-30 06:25:39.503            None   \n",
       "\n",
       "   DATE_OF_BIRTH_b                                        DESCRIPTION  \\\n",
       "0       1966-08-24  \\n\\n\\n\\n\\n\\nernesta  \\nseghetti  \\nistruzione ...   \n",
       "1             None  \\n\\n\\n\\n\\n\\nmarco broccio  \\nitaly  available ...   \n",
       "2       1980-05-18  \\n\\n\\n\\n\\n\\ncurriculum vitae  \\ndati personali...   \n",
       "3       1993-04-05  \\n simone facchini\\n\\n 63072 via borgo garibal...   \n",
       "4       2008-08-16  \\n\\n\\n\\n\\n\\nbruno gabriele cristiano  \\nnazion...   \n",
       "..             ...                                                ...   \n",
       "88      1994-08-05  \\n\\n\\n\\n\\n\\nilaria abate  \\nnazionalit italian...   \n",
       "89      1971-01-31  \\n\\n\\n\\n\\n\\nmaria angela cirasola  \\nnazionali...   \n",
       "90      2006-07-20  \\n\\n\\n\\n\\n\\ncurriculum vitae europass  \\ncurri...   \n",
       "91      1993-01-14  \\n\\n\\n\\n\\n\\nnina nicoleta movila  \\ndata di na...   \n",
       "92            None  \\n\\n\\n\\n\\n\\nflavia pralea  legal counsel  \\nfl...   \n",
       "\n",
       "                                 LAST_JOB_a  \\\n",
       "0                  operatore pulizie uffici   \n",
       "1            transaction monitoring analyst   \n",
       "2               socio in azienda global srl   \n",
       "3   programmatore cad/cam programmatore cnc   \n",
       "4                                  stagista   \n",
       "..                                      ...   \n",
       "88                     ispettore ambientale   \n",
       "89                     assistente familiare   \n",
       "90                                     None   \n",
       "91                                  badante   \n",
       "92                  corporate legal counsel   \n",
       "\n",
       "                                           LAST_JOB_b             LOCATION_a  \\\n",
       "0                            operatore pulizie uffici              bracciano   \n",
       "1          transaction monitoring analyst - freelance                  italy   \n",
       "2   socio in azienda global srl pulimentatura metalli  san giovanni valdarno   \n",
       "3            programmatore cad/cam, programmatore cnc             castignano   \n",
       "4                                stagista fc impianti                 vedano   \n",
       "..                                                ...                    ...   \n",
       "88                               ispettore ambientale               grosseto   \n",
       "89                               assistente familiare              bolano sp   \n",
       "90                                               None                  siena   \n",
       "91                                            badante                   roma   \n",
       "92                            corporate legal counsel         vicenza, italy   \n",
       "\n",
       "                    LOCATION_b                        SECOND_LAST_JOB_a  \\\n",
       "0                    bracciano           assistente educativa culturale   \n",
       "1                        italy      market risk and behavioural analyst   \n",
       "2   san giovanni valdarno (ar)                                     None   \n",
       "3                   castignano  programmatore cad/cam programmatore cnc   \n",
       "4               vedano, italia                                 stagista   \n",
       "..                         ...                                      ...   \n",
       "88                    grosseto                                  barista   \n",
       "89                 bolano (sp)                   cameriera e lavapiatti   \n",
       "90                       siena                                     None   \n",
       "91                        roma                                     None   \n",
       "92                     vicenza                         legal specialist   \n",
       "\n",
       "                                  SECOND_LAST_JOB_b  \\\n",
       "0           assistente educativa culturale aec/oepa   \n",
       "1   market risk and behavioural analyst - freelance   \n",
       "2                                              None   \n",
       "3          programmatore cad/cam, programmatore cnc   \n",
       "4                              stagista fc impianti   \n",
       "..                                              ...   \n",
       "88                                          barista   \n",
       "89                           cameriera e lavapiatti   \n",
       "90                                             None   \n",
       "91                                             None   \n",
       "92                                 legal specialist   \n",
       "\n",
       "                                             SKILLS_a  \\\n",
       "0   capacità organizzative e gestionali, leadershi...   \n",
       "1   investigation and analysis, screening and tran...   \n",
       "2   gestione amministrazione, vendite, back office...   \n",
       "3   programmazione cad/cam, cnc, fanuc, selca, hei...   \n",
       "4   infilaggio cavi, cablaggio, posa tubi, install...   \n",
       "..                                                ...   \n",
       "88  elaborazione delle informazioni, pensare in mo...   \n",
       "89  assistenza personale, servizio tavoli, pulizie...   \n",
       "90           elettronica, elettrotecnica, automazione   \n",
       "91  social, windows, gestione posta elettronica, u...   \n",
       "92  corporate legal advisory, contract negotiation...   \n",
       "\n",
       "                                             SKILLS_b  \\\n",
       "0   capacità organizzative e gestionali, leadershi...   \n",
       "1   investigation and analysis, screening and tran...   \n",
       "2   gestione amministrazione, ufficio vendite, bac...   \n",
       "3   programmazione fanuc, selca, heidenhain, progr...   \n",
       "4   installazione elettrica, cablaggio, posa tubi,...   \n",
       "..                                                ...   \n",
       "88  elaborazione delle informazioni, pensare in mo...   \n",
       "89  assistenza personale, somministrazione terapie...   \n",
       "90          elettronica e elettrotecnica, automazione   \n",
       "91  social, windows, gestione posta elettronica, u...   \n",
       "92  corporate legal advisory, contract negotiation...   \n",
       "\n",
       "           THIRD_LAST_JOB_a         THIRD_LAST_JOB_b ZIP_CODE_a  ZIP_CODE_b  \n",
       "0   receptionist front desk  receptionist front desk       None         NaN  \n",
       "1                      None                     None       None         NaN  \n",
       "2                      None                     None       None         NaN  \n",
       "3       agente assicurativo      agente assicurativo      63072     63072.0  \n",
       "4                      None                     None       None         NaN  \n",
       "..                      ...                      ...        ...         ...  \n",
       "88               babysitter               babysitter      58100     58100.0  \n",
       "89     addetta alle pulizie     addetta alle pulizie       None         NaN  \n",
       "90                     None                     None      53100     53100.0  \n",
       "91                     None                     None        166       166.0  \n",
       "92                 attorney                 attorney       None         NaN  \n",
       "\n",
       "[93 rows x 19 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a = session.sql(\"SELECT * FROM MPG_IT_AUTOMATCH_CANDIDATE_FEATURES\").to_pandas()\n",
    "df_b = session.sql(\"SELECT * FROM AUTOMATCH_FINAL_TABLE\").to_pandas()\n",
    "\n",
    "df_a[\"CANDIDATEID\"] = df_a[\"CANDIDATEID\"].astype(str)\n",
    "df_b[\"CANDIDATEID\"] = df_b[\"CANDIDATEID\"].astype(str)\n",
    "\n",
    "df_merged = pd.merge(df_a, df_b, on=\"CANDIDATEID\", suffixes=(\"_a\", \"_b\"))\n",
    "df_merged = df_merged[sorted(df_merged.columns)]\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4fbeba94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"response\": {\n",
      "    \"address\": \"Milano\",\n",
      "    \"name\": \"Antonio\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = session.sql(f\"\"\"SELECT AI_EXTRACT(\n",
    "  text => 'Antonio Cavalli Software Engineer Location: Milano',\n",
    "  responseFormat => PARSE_JSON('{{\"name\": \"What is the first name of the employee?\", \"address\": \"What is the address of the employee?\"}}')\n",
    " \n",
    ");\"\"\").collect()\n",
    "print(result[0][0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
