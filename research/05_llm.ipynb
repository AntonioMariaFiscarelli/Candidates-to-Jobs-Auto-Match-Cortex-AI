{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875de2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\fiscarelli\\\\Desktop\\\\Progetti\\\\Manpower IT\\\\Auto-Match\\\\Candidates-to-Jobs-Auto-Match-Cortex-AI'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"snowflake\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"snowflake.connector\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"snowflake.snowpark\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "%pwd\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# Add the absolute path to src/ so Python can find automatch\n",
    "src_path = os.path.abspath(\"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c1705f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\fiscarelli\\\\Desktop\\\\Progetti\\\\Manpower IT\\\\Auto-Match\\\\Candidates-to-Jobs-Auto-Match-Cortex-AI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9155a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://login.microsoftonline.com/e2ba81b8-03fe-407c-96a1-f4bc0f512e7d/saml2?SAMLRequest=nZJPj9owEMW%2FSuSeEzvhzyYWsGJBqFS0RZBF3b2ZZAIWjp3aDln66esEkLaH3UNvlv1mfs%2FzZvT4VgrvDNpwJccoDAjyQGYq5%2FIwRs%2Fpwo%2BRZyyTORNKwhhdwKDHyciwUlR0Wtuj3MDvGoz1XCNpaPswRrWWVDHDDZWsBENtRrfT7ysaBYQyY0Bbh0O3ktxwxzpaW1GMm6YJml6g9AFHhBBMEuxUreQLeoeoPmdUWlmVKXEveXN%2F%2BgARYtJvEU7hCOtb4ROX1xF8RtlfRYZ%2BTdO1v%2F65TZE3vf9upqSpS9Bb0GeewfNmdTVgnIOnbdInURw0bm4%2B1FpVELA%2FtYbASNUUgp0gU2VVW9c9cCdcQI6FOnA3s%2BV8jKoTz9P4uJW7Xzt2WSztebM4HfhLtj%2FMzmqwOp1FEoevcrD7NivgJUPe7p5w1Ca8NKaGpWxzte6KREOfhH7YS0lCSUTDQRANk1fkzZ0%2FLpntKu%2FmOx9ByTOtjCqskoJL6FxCtGdxuI990ivA75OHzE%2BGLPSL%2Fj4jxSCM4CHHbXoRum4Q7Yzoyf%2FOZYTfd7kt5Q%2BX03K%2BVoJnF2%2BhdMnsxzGGQdjd8NwvOimFknExzXMNxrg4hVDNTAOzbvetrgHhyZX67%2FZP%2FgI%3D&RelayState=ver%3A1-hint%3A126482538481578-ETMsDgAAAZu2l2rlABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEBxRPa61ehV%2BRtH25X9MHTMAAACgxmuGCq%2Fx282YLWXTPxpDNKCvDH3vc7JO8vb1Mj%2BAvdPWc2WrqIYiS99QO%2BZ%2BOEoxA5PWgZGY%2B5BRn6T6QTDxTuMPqVoh0OGiIPRogmXVc4VLdkeD2QqAjEhi0US2T1CXTJl%2Fq94qOoMiziQhhUnnLJo0qVdYln2DJAPU8LkX2IchLK%2B4eWCdXBLGzlTfEthJ14ozvwLdFs3hrP45OZfnbgAUn%2FcK8LmVEnnBDHzaZZRK45OFmog%3D to authenticate...\n"
     ]
    }
   ],
   "source": [
    "from autoMatch.utils.snowflake_utils import get_snowpark_session\n",
    "session = get_snowpark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc40000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LLMConfig:\n",
    "    root_dir: str\n",
    "    database: str\n",
    "    schema: str\n",
    "    input_table: str\n",
    "    columns : dict\n",
    "    llm_name : str\n",
    "    columns: dict\n",
    "    role_mappings: dict\n",
    "    education_levels : dict\n",
    "    desired_locations: dict\n",
    "    turno_preferenza: dict\n",
    "    parttime_preferenza_perc: list[int]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdecf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoMatch.constants import *\n",
    "from autoMatch.utils.common import read_yaml, create_directories\n",
    "\n",
    "from snowflake.snowpark.functions import col, trim, lower, length, parse_json, when, lit, trim, to_date, to_varchar\n",
    "from snowflake.snowpark.types import StringType, BooleanType\n",
    "from snowflake.snowpark.functions import udf\n",
    "from datetime import date\n",
    "\n",
    "from autoMatch.utils.common import validate_string \n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_llm_config(self) -> LLMConfig:\n",
    "        config = self.config.llm\n",
    "        schema = self.schema.llm\n",
    "        params = self.params.llm\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        llm_config = LLMConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            database=config.database,\n",
    "            schema=config.schema,\n",
    "            input_table=config.input_table,\n",
    "            llm_name=params.llm_name,\n",
    "            columns=schema.columns,\n",
    "            role_mappings = schema.role_mappings,\n",
    "            education_levels = schema.education_levels,\n",
    "            desired_locations = schema.desired_locations,\n",
    "            turno_preferenza = schema.turno_preferenza,\n",
    "            parttime_preferenza_perc = schema.parttime_preferenza_perc\n",
    "        )\n",
    "\n",
    "        return llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af745682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoMatch import logger\n",
    "from autoMatch.entity.config_entity import LLMConfig\n",
    "\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.functions import col, lit, coalesce\n",
    "\n",
    "import json\n",
    "import difflib\n",
    "        \n",
    "class LLM:\n",
    "    def __init__(self, config: LLMConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "\n",
    "    def __normalize(self, s: str) -> str:\n",
    "        return ''.join(ch for ch in s.lower() if ch.isalnum())\n",
    "\n",
    "    def __find_synonyms_builtin(self, query: str, mapping: dict, cutoff: float = 0.8):\n",
    "        \"\"\"\n",
    "        Return a flat list of synonym strings for keys that match the query.\n",
    "        - Ignores underscores, hyphens, spaces and case.\n",
    "        - Uses difflib.get_close_matches with a similarity cutoff (0..1).\n",
    "        - Checks normalized keys and normalized synonym terms.\n",
    "        \"\"\"\n",
    "        qn = self.__normalize(query)\n",
    "        norm_index = {}   # normalized token -> original key\n",
    "        norm_tokens = []  # list of normalized tokens to match against\n",
    "\n",
    "        for key, synonyms in mapping.items():\n",
    "            nk = self.__normalize(key)\n",
    "            if nk not in norm_index:\n",
    "                norm_index[nk] = key\n",
    "                norm_tokens.append(nk)\n",
    "            for term in synonyms:\n",
    "                nt = self.__normalize(term)\n",
    "                if nt not in norm_index:\n",
    "                    norm_index[nt] = key\n",
    "                    norm_tokens.append(nt)\n",
    "\n",
    "        matches_keys = set()\n",
    "        close = difflib.get_close_matches(qn, norm_tokens, n=20, cutoff=cutoff)\n",
    "        for nk in close:\n",
    "            matches_keys.add(norm_index[nk])\n",
    "\n",
    "        # also accept direct substring matches (useful for multiword queries)\n",
    "        for nk, orig_key in norm_index.items():\n",
    "            if qn in nk or nk in qn:\n",
    "                matches_keys.add(orig_key)\n",
    "\n",
    "        # collect synonyms for matched keys, flatten and deduplicate preserving order\n",
    "        result = []\n",
    "        seen = set()\n",
    "        for key in mapping:\n",
    "            if key in matches_keys:\n",
    "                for term in mapping[key]:\n",
    "                    if term not in seen:\n",
    "                        seen.add(term)\n",
    "                        result.append(term)\n",
    "        return result\n",
    "\n",
    "    def create_prompt_row(self, role, \n",
    "                      skills, \n",
    "                      skills_soft,\n",
    "                      skills_language,\n",
    "                      skills_education,\n",
    "                      skills_certifications):\n",
    "        \"\"\"\n",
    "        Creates custom prompt based on potential candidates info and recruiter position info\n",
    "        Returns prompt in string format\n",
    "        \"\"\"\n",
    "\n",
    "        role_mappings = self.config.role_mappings\n",
    "\n",
    "        similar_roles = self.__find_synonyms_builtin(role, role_mappings, cutoff=0.85)\n",
    "\n",
    "        if similar_roles:\n",
    "            role_mappings_string = f\"{', '.join(similar_roles)}. \"\n",
    "        else:\n",
    "            role_mappings_string = f\"e ruoli simili\"\n",
    "\n",
    "        skills_text = f\"\"\"Dai +1 punto per ogni skill che il candidato ha tra le seguenti : {skills}. \n",
    "        (Ad esempio, se si ricerca la skill \"SAP\", si deve dare +1 a: \"SAP\", \"software sap\", \"gestionale sap\" ecc)\n",
    "        \"\"\" if bool(skills) else \"\"\n",
    "        languages_text = f\"Dai un bonus ai candidati che conoscono le seguenti lingue: {', '.join(skills_language)}. \" if bool(skills_language) else \"\"\n",
    "        education_text = f\"Dai un bonus ai candidati che hanno questo titolo di studio o superiore: {skills_education}. \" if bool(skills_education) else \"\"\n",
    "        certifications_text = f\"Dai un bonus ai candidati che hanno le seguenti certificazioni: {skills_certifications}, anche se è all'interno di una lista di certificazioni. \" if bool(skills_certifications) else \"\"\n",
    "\n",
    "\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Dai un voto al candidato per il seguente ruolo: {role} ({role_mappings_string}).\n",
    "        Dai sempre un voto più alto ai candidati i cui campi last_job, second_last_job o third_last_job contengono {role}, anche se all interno di una lista di ruoli.  \n",
    "        Dai un voto più alto ai candidati che hanno coperto più volte questo ruolo. \n",
    "        Dai un voto più alto ai candidati che hanno coperto questo ruolo come last_job, rispetto a chi l ha coperto solo come second_last_job e third_last_job.\n",
    "        Dai un voto basso ai candidati che non hanno esperienza regressa in ruoli simili. \n",
    "        Ad esempio \n",
    "            - last_job:{role}, second_last_job:{role} e third_last_job:{role} -> voto 100.\n",
    "            - last_job:{role}, second_last_job:{role} e third_last_job:altro -> voto 85.\n",
    "            - last_job:{role}, second_last_job:altro e third_last_job:{role} -> voto 70.\n",
    "            - last_job:{role}, second_last_job:altro e third_last_job:altro -> voto 55.\n",
    "            - last_job:altro, second_last_job:{role} e third_last_job:{role} -> voto 40.\n",
    "            - last_job:altro, second_last_job:{role} e third_last_job:altro -> voto 25.\n",
    "            - last_job:altro, second_last_job:altro e third_last_job:{role} -> voto 10. \n",
    "        {skills_text}\n",
    "        {languages_text}\n",
    "        {education_text}\n",
    "        {certifications_text}\n",
    "        Rispondi solo con un valore numerico da 0 a 100, dove 100 indica il candidato perfetto.\n",
    "        \"\"\"\n",
    "\n",
    "        parts = [\n",
    "            \"'Ultimo lavoro: ', last_job\",\n",
    "            \"'Penultimo lavoro: ', second_last_job\",\n",
    "            \"'Terzultimo lavoro: ', third_last_job\"\n",
    "        ]\n",
    "\n",
    "        if skills_text:\n",
    "            parts.append(\"'Skills: ', skills\")\n",
    "        if languages_text:\n",
    "            parts.append(\"'Languages: ', languages\")\n",
    "        if education_text:\n",
    "            parts.append(\"'Education: ', education\")\n",
    "        if certifications_text:\n",
    "            parts.append(\"'Certifications: ', certifications\")\n",
    "\n",
    "        # unisci solo le parti presenti con \" | \"\n",
    "        text = \", ' | ', \".join(parts)\n",
    "        text = \"CONCAT(\" + text + \")\"\n",
    "\n",
    "        #CONCAT('Ultimo lavoro: ', last_job, ' | Penultimo lavoro: ', second_last_job, ' | Terzultimo lavoro: ', third_last_job, ' | Skills: ', skills, ' | Languages: ', languages, ' | Education: ', education)\n",
    "\n",
    "\n",
    "        logger.info(\"Prompt successfully created\")\n",
    "\n",
    "        return prompt, text \n",
    "\n",
    "    def call_ai_row(self, session, prompt, text):\n",
    "        \"\"\"\n",
    "        Calls AI model on custom prompt\n",
    "        Returns json response\n",
    "        \"\"\"\n",
    "        llm_name = self.config.llm_name\n",
    "\n",
    "        database = self.config.database\n",
    "        schema = self.config.schema\n",
    "        input_table = self.config.input_table\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT\n",
    "                *,\n",
    "                SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                    'claude-4-sonnet',\n",
    "                    CONCAT(\n",
    "                    '{prompt.replace(\"'\", \"''\")}',\n",
    "                    'Testo: ', CONCAT('Ultimo lavoro: ', last_job, ' | Penultimo lavoro: ', second_last_job, ' | Terzultimo lavoro: ', third_last_job, \n",
    "                    ' | Skills: ', skills, ' | Languages: ', languages, ' | Education: ', education)   \n",
    "                    )\n",
    "                ) AS SCORE\n",
    "            FROM \n",
    "            (SELECT *\n",
    "            FROM {database}.{schema}.{input_table}_APP\n",
    "            --LIMIT 100\n",
    "            )\n",
    "            \"\"\"\n",
    "        #CONCAT('Ultimo lavoro: ', last_job, ' | Penultimo lavoro: ', second_last_job, ' | Terzultimo lavoro: ', third_last_job\n",
    "        #CONCAT('Ultimo lavoro: ', last_job, ' | ', 'Penultimo lavoro: ', second_last_job, ' | ', 'Terzultimo lavoro: ', third_last_job)\n",
    "        query = f\"\"\"\n",
    "            SELECT\n",
    "                *,\n",
    "                SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                    'claude-4-sonnet',\n",
    "                    CONCAT(\n",
    "                    '{prompt.replace(\"'\", \"''\")}',\n",
    "                    'Testo: ', {text}\n",
    "                    )\n",
    "                ) AS SCORE\n",
    "            FROM \n",
    "            (SELECT *\n",
    "            FROM {database}.{schema}.{input_table}_APP\n",
    "            --LIMIT 100\n",
    "            )\n",
    "            \"\"\"\n",
    "        \n",
    "\n",
    "        logger.info(f\"Running model {llm_name} on candidate data\")\n",
    "\n",
    "        df = session.sql(query)\n",
    "\n",
    "        df = df.with_column(\n",
    "            \"SCORE\",\n",
    "            F.coalesce(F.try_cast(F.col(\"SCORE\"), \"int\"), F.lit(0))\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Run completed\")\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def create_prompt_row(self, role, \n",
    "                      skills_mand, \n",
    "                      skills_opt,\n",
    "                      skills_languages_mand,\n",
    "                      skills_languages_opt,\n",
    "                      skills_education_mand,\n",
    "                      skills_education_opt,\n",
    "                      skills_certifications_mand,\n",
    "                      skills_certifications_opt):\n",
    "        \"\"\"\n",
    "        Creates custom prompt based recruiter requirements.\n",
    "        It creates a prompt for each mandatory skill (asks the LLM to reply with True or False if the candidate has the spefic skill or not)\n",
    "        It creates a prompt for each optional skill (asks the LLM to provide a score bases on the matching skills)\n",
    "\n",
    "        Returns a prompt dictionary:\n",
    "        prompts = {\n",
    "            'NEW_COLUMN' : [prompt, columns],\n",
    "            }\n",
    "        NEW_COLUMN: new column created, bool for mandatory skills and numeric for optional skills\n",
    "        prompt: prompt used for the Cortex AI request\n",
    "        columns: candidate column(s) name (or combination) provided to Cortex AI\n",
    "        \"\"\"\n",
    "\n",
    "        role_mappings = self.config.role_mappings\n",
    "\n",
    "        # Looks up for similar roles to the one specified. i.e. \"Magazziniere\" will also include \"carico scarico\" and \"warehouse worker\"\n",
    "        similar_roles = self.__find_synonyms_builtin(role, role_mappings, cutoff=0.85)\n",
    "\n",
    "        if similar_roles:\n",
    "            role_mappings_string = f\"{', '.join(similar_roles)}. \"\n",
    "        else:\n",
    "            role_mappings_string = f\"e ruoli simili\"\n",
    "\n",
    "        \n",
    "        prompt_jobs = f\"\"\"\n",
    "        Dai un voto al candidato per il seguente ruolo: {role} ({role_mappings_string}).\n",
    "        Dai sempre un voto più alto ai candidati i cui campi last_job, second_last_job o third_last_job contengono {role}, anche se all interno di una lista di ruoli.  \n",
    "        Dai un voto più alto ai candidati che hanno coperto più volte questo ruolo. \n",
    "        Dai un voto più alto ai candidati che hanno coperto questo ruolo come last_job, rispetto a chi l ha coperto solo come second_last_job e third_last_job.\n",
    "        Dai un voto basso ai candidati che non hanno esperienza regressa in ruoli simili. \n",
    "        Ad esempio \n",
    "            - last_job:{role}, second_last_job:{role} e third_last_job:{role} -> voto 100.\n",
    "            - last_job:{role}, second_last_job:{role} e third_last_job:altro -> voto 85.\n",
    "            - last_job:{role}, second_last_job:altro e third_last_job:{role} -> voto 70.\n",
    "            - last_job:{role}, second_last_job:altro e third_last_job:altro -> voto 55.\n",
    "            - last_job:altro, second_last_job:{role} e third_last_job:{role} -> voto 40.\n",
    "            - last_job:altro, second_last_job:{role} e third_last_job:altro -> voto 25.\n",
    "            - last_job:altro, second_last_job:altro e third_last_job:{role} -> voto 10. \n",
    "        Rispondi solo con un valore numerico da 0 a 100, dove 100 indica il candidato perfetto.\n",
    "        \"\"\"\n",
    "\n",
    "        jobs_column = [\n",
    "            \"'Ultimo lavoro: ', last_job\",\n",
    "            \"'Penultimo lavoro: ', second_last_job\",\n",
    "            \"'Terzultimo lavoro: ', third_last_job\"\n",
    "        ]\n",
    "        jobs_column = \", ' | ', \".join(jobs_column)\n",
    "\n",
    "\n",
    "        prompt_skills_mand = f\"\"\"\n",
    "        Assegna True se il candidato ha tutte le seguenti skills (separate da virgola) : {skills_mand}, altrimenti False. \n",
    "        Se non ci sono skills disponibili, rispondi False.\n",
    "        Ad esempio se si ricercano le seguenti due skills \"SAP, Office\":\n",
    "            - skills: \"Python, gestionale sap, SQL, microsoft office, Pyspark\" -> True\n",
    "            - skills: \"Python, SQL, microsoft office, Pyspark\" -> False\n",
    "            - skills: \"Python, gestionale sap, SQL, Pyspark\" -> False\n",
    "            - skills: \"Python, SQL, Pyspark\" -> False\n",
    "        Rispondi solo con due possibili valori: True, False\n",
    "        \"\"\" if bool(skills_mand) else \"\"\n",
    "\n",
    "        prompt_skills_opt = f\"\"\"\n",
    "        Assegna +1 punto per ogni skill che il candidato ha tra le seguenti (separate da virgola) : {skills_opt}. \n",
    "        Se non ci sono skills disponibili, restituisci 0.\n",
    "        Ad esempio se si ricercano le seguenti due skills \"SAP, Office\":\n",
    "            - skills: \"Python, gestionale sap, SQL, microsoft office, Pyspark\" -> 2\n",
    "            - skills: \"Python, SQL, microsoft office, Pyspark\" -> 1\n",
    "            - skills: \"Python, gestionale sap, SQL, Pyspark\" -> 1\n",
    "            - skills: \"Python, SQL, Pyspark\" -> 0\n",
    "        Rispondi solo con un valore numerico\n",
    "        \"\"\" if bool(skills_opt) else \"\"\n",
    "\n",
    "        prompt_languages_mand = f\"\"\"\n",
    "        Assegna True se il candidato ha tutte le seguenti skills linguistiche (separate da virgola) : {\", \".join(skills_languages_mand)}. Altrimenti False. \n",
    "        Se non ci sono languages disponibili, rispondi False.\n",
    "        Rispondi solo con due possibili valori: True, False\n",
    "        \"\"\" if bool(skills_languages_mand) else \"\"\n",
    "\n",
    "        \"\"\"\n",
    "        Ad esempio se si ricercano le seguenti due lingue \"Inglese, Francese, Spagnolo\":\n",
    "            - languages: \"Italiano, Inglese, Tedesco, Francese, Spagnolo\" -> True\n",
    "            - languages: \"Italiano, Inglese, Tedesco, Francese, Arabo\" -> False\n",
    "            - languages: \"Italiano, Inglese, Tedesco, Spagnolo\" -> False\n",
    "            - languages: \"Italiano, Tedesco, Francese\" -> False\n",
    "            - languages: \"Italiano, Tedesco, Spagnolo\" -> False\n",
    "        \"\"\"\n",
    "        prompt_languages_opt = f\"\"\"\n",
    "        Assegna +1 punto per ogni skill linguistica che il candidato ha tra le seguenti (separate da virgola) : {\", \".join(skills_languages_opt)}. \n",
    "        Se non ci sono languages disponibili, restituisci 0.\n",
    "        Ad esempio se si ricercano le seguenti due lingue \"SAP, Office\":\n",
    "            - languages: \"Italiano, Inglese, Tedesco, Francese\" -> 2\n",
    "            - languages: \"Italiano, Inglese, Tedesco, Spagnolo\" -> 1\n",
    "            - languages: \"Italiano, Tedesco, Francese\" -> 1\n",
    "            - languages: \"Italiano, Tedesco, Spagnolo\" -> 0\n",
    "        Rispondi solo con un valore numerico\n",
    "        \"\"\" if bool(skills_languages_opt) else \"\"\n",
    "\n",
    "        prompt_education_mand = f\"\"\"\n",
    "        Assegna True se il candidato ha almeno il seguento livello di educazione : {skills_education_mand}. Altrimenti False. \n",
    "        Se education non è disponibile, rispondi False.\n",
    "        I livelli di education con il loro ranking sono i seguenti:\n",
    "            - \"Diploma scuola media\": 1\n",
    "            - \"Diploma scuola superiore\": 2\n",
    "            - \"Laurea triennale\": 3\n",
    "            - \"Laurea specialistica\": 4\n",
    "            - \"Dottorato\": 5\n",
    "        Ad esempio se si ricerca un candidato con livello di educazione \"Laurea Triennale\":\n",
    "            - education: \"Diploma scuola media\" -> False\n",
    "            - education: \"Diploma scuola superiore\" -> False\n",
    "            - education: \"Laurea triennale\" -> True\n",
    "            - education: \"Laurea specialistica\" -> True\n",
    "            - education: \"Dottorato\" -> True\n",
    "        Rispondi solo con due possibili valori: True, False\n",
    "        \"\"\" if bool(skills_education_mand) else \"\"\n",
    "\n",
    "        prompt_education_opt = f\"\"\"\n",
    "        Assegna +1 punto per ogni livello di education extra rispetto a quello cercato: {skills_education_opt}.\n",
    "        Se education non è disponibile, restituisci 0.\n",
    "        I livelli di education con il loro ranking sono i seguenti: \n",
    "            - \"Diploma scuola media\": 1\n",
    "            - \"Diploma scuola superiore\": 2\n",
    "            - \"Laurea triennale\": 3\n",
    "            - \"Laurea specialistica\": 4\n",
    "            - \"Dottorato\": 5\n",
    "        Ad esempio se si ricerca un candidato con livello di educazione \"Laurea Triennale\":\n",
    "            - education: \"Diploma scuola media\" -> -2\n",
    "            - education: \"Diploma scuola superiore\" -> -1\n",
    "            - education: \"Laurea triennale\" -> 0\n",
    "            - education: \"Laurea specialistica\" -> 1\n",
    "            - education: \"Dottorato\" -> 2\n",
    "        Un altro esempio, se si ricerca un candidato con livello di educazione \"Diploma scuola superiore\":\n",
    "            - education: \"Diploma scuola media\" -> -1\n",
    "            - education: \"Diploma scuola superiore\" -> 0\n",
    "            - education: \"Laurea triennale\" -> 1\n",
    "            - education: \"Laurea specialistica\" -> 2\n",
    "            - education: \"Dottorato\" -> 3\n",
    "        Un altro esempio, se si ricerca un candidato con livello di educazione \"Laurea specialistica\":\n",
    "            - education: \"Diploma scuola media\" -> -3\n",
    "            - education: \"Diploma scuola superiore\" -> -2\n",
    "            - education: \"Laurea triennale\" -> -1\n",
    "            - education: \"Laurea specialistica\" -> 0\n",
    "            - education: \"Dottorato\" -> 1\n",
    "        Rispondi solo con un valore numerico\n",
    "        \"\"\" if bool(skills_education_opt) else \"\"\n",
    "\n",
    "        prompt_certifications_mand = f\"\"\"\n",
    "        Assegna True se il candidato ha tutte le seguenti certificazioni (separate da virgola) : {skills_certifications_mand}, altrimenti False. \n",
    "        Se non ci sono certificazioni disponibili, rispondi False.\n",
    "        Ad esempio se si ricercano le seguenti due skills \"CISM, Patente B\":\n",
    "            - skills: \"CISM, Certificazione SAP, patente B, IELTS\" -> True\n",
    "            - skills: \"CISM, Certificazione SAP, ISACA, IELTS\" -> False\n",
    "            - skills: \"CISM, Certificazione SAP, patente muletto, IELTS\" -> False\n",
    "            - skills: \"Comp TIA, Certificazione SAP, ISACA, IELTS\" -> False\n",
    "        Rispondi solo con due possibili valori: True, False\n",
    "        \"\"\" if bool(skills_certifications_mand) else \"\"\n",
    "\n",
    "        prompt_certifications_opt = f\"\"\"\n",
    "        Assegna +1 punto per ogni certificazione che il candidato ha tra le seguenti (separate da virgola) : {skills_certifications_opt}. \n",
    "        Se non ci sono certificazioni disponibili, restituisci 0.\n",
    "        Ad esempio se si ricercano le seguenti due certificazioni \"CISM, Patente B\":\n",
    "            - skills: \"CISM, Certificazione SAP, patente B, IELTS\" -> 2\n",
    "            - skills: \"CISM, Certificazione SAP, ISACA, IELTS\" -> 1\n",
    "            - skills: \"CISM, Certificazione SAP, patente muletto, IELTS\" -> 1\n",
    "            - skills: \"Comp TIA, Certificazione SAP, patente muletto, IELTS\" -> 0\n",
    "        Rispondi solo con un valore numerico\n",
    "        \"\"\" if bool(skills_certifications_opt) else \"\"\n",
    "\n",
    "\n",
    "        prompts = {\n",
    "            'SCORE_JOBS' : [prompt_jobs, jobs_column],\n",
    "            'MAND_SKILLS': [prompt_skills_mand, 'skills'],\n",
    "            'SCORE_SKILLS': [prompt_skills_opt, 'skills'],\n",
    "            'MAND_LANGUAGES': [prompt_languages_mand, 'languages'],\n",
    "            'SCORE_LANGUAGES': [prompt_languages_opt, 'languages'],\n",
    "            'MAND_EDUCATION': [prompt_education_mand, 'education'],\n",
    "            'SCORE_EDUCATION': [prompt_education_opt, 'education'],\n",
    "            'MAND_CERTIFICATIONS': [prompt_certifications_mand, 'certifications'],\n",
    "            'SCORE_CERTIFICATIONS': [prompt_certifications_opt, 'certifications']\n",
    "            }\n",
    "\n",
    "        logger.info(\"Prompt successfully created\")\n",
    "\n",
    "        return prompts\n",
    "    \n",
    "\n",
    "    def call_ai_row(self, session, prompts):\n",
    "        \"\"\"\n",
    "        Queries the Vertex AI service based on the prompts\n",
    "        Returns candidate dataframe with extracted information\n",
    "        \"\"\"\n",
    "        llm_name = self.config.llm_name\n",
    "\n",
    "        database = self.config.database\n",
    "        schema = self.config.schema\n",
    "        input_table = self.config.input_table\n",
    "\n",
    "        #creates a Cortex AI call for each prompt provided\n",
    "        ai_calls = []\n",
    "        for key, (pt, field) in prompts.items():\n",
    "            ai_call = f\"\"\"\n",
    "            SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                'claude-4-sonnet',\n",
    "                CONCAT(\n",
    "                '{pt.replace(\"'\", \"''\")}',\n",
    "                'Testo: ', {field}\n",
    "                )\n",
    "            ) AS {key}, \"\"\" if bool(pt) else \"\"\n",
    "            ai_calls.append(ai_call)\n",
    "            \n",
    "        ai_calls_sql = \"\".join(ai_calls)\n",
    "\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT\n",
    "                *,\n",
    "            {ai_calls_sql}            \n",
    "            FROM \n",
    "            (SELECT *\n",
    "            FROM {database}.{schema}.{input_table}_APP\n",
    "            --LIMIT 100\n",
    "            )\n",
    "            \"\"\"\n",
    "        \n",
    "        logger.info(f\"Running model {llm_name} on candidate data\")\n",
    "\n",
    "        df = session.sql(query)\n",
    "\n",
    "\n",
    "        # Combine each \"MAND_\" boolean column to filter out candidates that didn't match all requirements\n",
    "        mand_cols = [c for c in df.schema.names if c.startswith(\"MAND_\")]\n",
    "        if(len(mand_cols) > 0):\n",
    "            mand_expr = lit(True)\n",
    "            for c in mand_cols:\n",
    "                df = df.with_column(\n",
    "                    c,\n",
    "                    F.coalesce(F.sql_expr(f\"TRY_TO_BOOLEAN({c})\"), F.lit(False))\n",
    "                    )\n",
    "                mand_expr = mand_expr & (col(c) == lit(True))\n",
    "\n",
    "            df = df.with_column(\"MAND\", mand_expr)\n",
    "            df = df.drop(*mand_cols)\n",
    "        else:\n",
    "            df = df.with_column(\"MAND\", lit(True))\n",
    "\n",
    "        df = df.filter(col(\"MAND\") == True)\n",
    "\n",
    "        # Sums up each individual score column to compute the final candidate score\n",
    "        score_cols = [c for c in df.schema.names if c.startswith(\"SCORE_\")]\n",
    "        if(len(score_cols) > 0):\n",
    "            score_expr = lit(0)\n",
    "            for c in score_cols:\n",
    "                df = df.with_column(\n",
    "                    c,\n",
    "                    F.coalesce(F.sql_expr(f\"TRY_TO_NUMBER({c})\"), F.lit(0))\n",
    "                    )\n",
    "                score_expr = score_expr + coalesce(col(c), lit(0))\n",
    "\n",
    "            df = df.with_column(\n",
    "                \"SCORE\",\n",
    "                F.cast(F.round(score_expr), \"int\")\n",
    "            )\n",
    "            df = df.drop(*score_cols)\n",
    "        else:\n",
    "            df = df.with_column(\"SCORE\", lit(0))\n",
    "\n",
    "        \n",
    "        logger.info(f\"Run completed\")\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def clean_description(self, session):\n",
    "        \"\"\"\n",
    "        Reads input table\n",
    "        Cleans description column:\n",
    "            - removes rows with empty description\n",
    "            - replaces multiple consecutive whitespaces with a single whitespace (preserves newlines)\n",
    "            - removes all html tags\n",
    "            - lowercases all text\n",
    "        Function returns Snowflake dataframe\n",
    "        \"\"\"\n",
    "        database = self.config.database\n",
    "        schema = self.config.schema\n",
    "        input_table = self.config.input_table\n",
    "\n",
    "        df = session.table(f\"{database}.{schema}.{input_table}\")\n",
    "        df = df.filter((col(\"description\").is_not_null()) & (trim(col(\"description\")) != \"\"))\n",
    "\n",
    "        def build_normalize_whitespace_udf():\n",
    "            def normalize(text: str) -> str:\n",
    "                import re\n",
    "                if text is None:\n",
    "                    return ''\n",
    "                return re.sub(r'[ \\t]+', ' ', text).strip()\n",
    "\n",
    "            return udf(normalize, return_type=StringType(), input_types=[StringType()])\n",
    "        normalize_udf = build_normalize_whitespace_udf()\n",
    "        df = df.with_column(\"description\", normalize_udf(df[\"description\"]))\n",
    "        \n",
    "\n",
    "        def build_clean_html_udf():\n",
    "            from bs4 import BeautifulSoup\n",
    "            def clean_html(text: str) -> str:\n",
    "                if not text:\n",
    "                    return \"\"\n",
    "                return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "            return udf(\n",
    "                clean_html,\n",
    "                return_type=StringType(),\n",
    "                input_types=[StringType()],\n",
    "                packages=[\"beautifulsoup4\"]\n",
    "            )\n",
    "\n",
    "        clean_html_udf = build_clean_html_udf()\n",
    "        df = df.with_column(\"description\", clean_html_udf(df[\"description\"]))\n",
    "\n",
    "        df = df.with_column(\"description\", lower(df[\"description\"]))\n",
    "\n",
    "        df = df.filter((col(\"description\").is_not_null()) & \n",
    "                       (trim(col(\"description\")) != \"\") &\n",
    "                       (length(trim(col(\"description\"))) > 5) &\n",
    "                       (~col(\"description\").like(\"%None%\")) &\n",
    "                       (~col(\"description\").like(\"%null%\"))\n",
    "                       )\n",
    "\n",
    "        df = df.with_column(\"description\", col(\"description\").cast(\"STRING\"))\n",
    "        \n",
    "        logger.info(f\"Table {input_table} successfully cleaned\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def validate_json(self, df):\n",
    "    \n",
    "        def build_clean_parsing_udf():\n",
    "            def clean(x: str) -> str:\n",
    "                if x is None:\n",
    "                    return ''\n",
    "                x = x.lower().lstrip()\n",
    "                if x.startswith(\"```json\"):\n",
    "                    x = x[8:].lstrip()\n",
    "                x = x.replace('\\n', ' ').replace('\\t', ' ').replace('\\\\', '').strip()\n",
    "                x = ' '.join(x.split())\n",
    "                if x.endswith(\"```\"):\n",
    "                    x = x[:-3].rstrip()\n",
    "                if x.endswith(\"'\") or x.endswith('\"'):\n",
    "                    x = x[:-1].rstrip()\n",
    "                return x\n",
    "\n",
    "            return udf(clean, return_type=StringType(), input_types=[StringType()])\n",
    "        clean_udf = build_clean_parsing_udf()\n",
    "\n",
    "        df = df.with_column(\"ner_json\", clean_udf(df[\"ner_json\"]))\n",
    "\n",
    "        def build_is_valid_json_udf():\n",
    "            import json\n",
    "            def is_valid(text: str) -> bool:\n",
    "                if not text:\n",
    "                    return False\n",
    "                try:\n",
    "                    json.loads(text)\n",
    "                    return True\n",
    "                except Exception:\n",
    "                    return False\n",
    "\n",
    "            return udf(is_valid, return_type=BooleanType(), input_types=[StringType()])\n",
    "        \n",
    "        is_valid_json_udf = build_is_valid_json_udf()\n",
    "        df = df.with_column(\"is_valid_json\", is_valid_json_udf(df[\"ner_json\"]))\n",
    "        df = df.filter(col(\"is_valid_json\") == True)\n",
    "        df = df.drop(\"is_valid_json\")\n",
    "\n",
    "        df = df.with_column(\"ner_json\", parse_json(col(\"ner_json\")))\n",
    "\n",
    "        df = df.filter(df[\"ner_json\"].is_not_null())\n",
    "\n",
    "        \n",
    "        df = df.with_columns(\n",
    "            [\"turno_preferenza\", \"parttime_preferenza_perc\", \"skills\", \"languages\", \"education\", \"certifications\"],\n",
    "            [\n",
    "                col(\"ner_json\")[\"turno_preferenza\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"parttime_preferenza_perc\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"skills\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"languages\"].cast(\"STRING\"), \n",
    "                col(\"ner_json\")[\"education\"].cast(\"STRING\"),\n",
    "                col(\"ner_json\")[\"certifications\"].cast(\"STRING\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        def validate_string(df, column_name):\n",
    "            df = df.with_column(\n",
    "                column_name,\n",
    "                when(\n",
    "                    (col(column_name).is_not_null()) &\n",
    "                    (trim(col(column_name)) != \"\") &\n",
    "                    (~lower(trim(col(column_name))).isin([\"null\", \"none\", \"nan\"])),\n",
    "                    col(column_name)\n",
    "                    ).otherwise(lit(None))\n",
    "                )\n",
    "            return df\n",
    "        \n",
    "        \n",
    "        df = validate_string(df, \"turno_preferenza\")\n",
    "        df = validate_string(df, \"parttime_preferenza_perc\")\n",
    "        df = validate_string(df, \"skills\")\n",
    "        df = validate_string(df, \"languages\")\n",
    "        df = validate_string(df, \"education\")\n",
    "        df = validate_string(df, \"certifications\")\n",
    "\n",
    "\n",
    "        # makes sure age is a reasonable value\n",
    "        df = df.with_column(\n",
    "            \"parttime_preferenza_perc\",\n",
    "            when(\n",
    "                (col(\"parttime_preferenza_perc\") != \"nan\") &\n",
    "                (col(\"parttime_preferenza_perc\").cast(\"INT\").is_not_null()) &\n",
    "                (col(\"parttime_preferenza_perc\").cast(\"INT\") >= 0) &\n",
    "                (col(\"parttime_preferenza_perc\").cast(\"INT\") <= 100),\n",
    "                col(\"parttime_preferenza_perc\").cast(\"INT\")\n",
    "            ).otherwise(lit(None))\n",
    "        )\n",
    "\n",
    "        df = df.drop(\"ner_json\")\n",
    "        df = df.drop(\"description\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_prompt_vacancy(self, session):\n",
    "        \"\"\"\n",
    "        Creates custom prompt based recruiter requirements.\n",
    "        It creates a prompt for each mandatory skill (asks the LLM to reply with True or False if the candidate has the spefic skill or not)\n",
    "        It creates a prompt for each optional skill (asks the LLM to provide a score bases on the matching skills)\n",
    "\n",
    "        Returns a prompt dictionary:\n",
    "        prompts = {\n",
    "            'NEW_COLUMN' : [prompt, columns],\n",
    "            }\n",
    "        NEW_COLUMN: new column created, bool for mandatory skills and numeric for optional skills\n",
    "        prompt: prompt used for the Cortex AI request\n",
    "        columns: candidate column(s) name (or combination) provided to Cortex AI\n",
    "        \"\"\"\n",
    "\n",
    "        llm_name = self.config.llm_name\n",
    "\n",
    "        database = self.config.database\n",
    "        schema = self.config.schema\n",
    "        input_table = self.config.input_table\n",
    "\n",
    "        turno_preferenza = self.config.turno_preferenza\n",
    "        education_levels = self.config.education_levels\n",
    "        parttime_preferenza_perc = self.config.parttime_preferenza_perc\n",
    "\n",
    "        open_texts = [\"DESCRIZIONE_USO_INTERNO\", \"TESTO_PUBBLICAZIONE\", \"RICHIESTE_AGGIUNTIVE\", \"REQUISITI\"]\n",
    "        #all_texts = [\"skills_list\", \"part_time_percent\", \"titoli_richiesti\", \"DESCRIZIONE_USO_INTERNO\", \"TESTO_PUBBLICAZIONE\", \"RICHIESTE_AGGIUNTIVE\", \"REQUISITI\"]\n",
    "        \n",
    "        texts = [\"skills\", \"parttime_preferenza_perc\", \"education\", \"DESCRIZIONE_USO_INTERNO\", \"TESTO_PUBBLICAZIONE\", \"RICHIESTE_AGGIUNTIVE\", \"REQUISITI\"]\n",
    "        labels = [\"Skills richieste\", \"Percentuale part time\", \"Titoli di studio richiesti\", \"DESCRIZIONE USO INTERNO\", \"TESTO PUBBLICAZIONE\", \"RICHIESTE AGGIUNTIVE\", \"REQUISITI\"]\n",
    "        \n",
    "        all_texts = []\n",
    "        for label, text in zip(labels, texts):\n",
    "            all_texts.append(f\"\"\"'{label}: ', {text} \"\"\")\n",
    "\n",
    "        print(all_texts)\n",
    "        concat_text = f\"\"\"CONCAT( {\", '| ', \".join(all_texts)}  )\"\"\"\n",
    "        #concat_text = \"CONCAT('skills: ', skills , 'descrizione uso interno: ', DESCRIZIONE_USO_INTERNO, ' | ', 'testo pubblicazione', TESTO_PUBBLICAZIONE)\"\n",
    "        print(concat_text)\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT\n",
    "                *,\n",
    "                {concat_text} as description,\n",
    "                SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                    'claude-4-sonnet',\n",
    "                    CONCAT(\n",
    "                        'Stai analizzando  una posizione lavorativa aperta, estrai i seguenti campi: \n",
    "                        turno_preferenza (turni richiesti per la posizione. stringa, possibili valori (anche multipli): {\", \".join(turno_preferenza)}), \n",
    "                        parttime_preferenza_perc (percentuale di part time richiesta. stringa, possibili valori (solo uno): {\", \".join(str(x) for x in parttime_preferenza_perc)}),\n",
    "                        skills (skills tecniche richieste. stringa),\n",
    "                        languages (lingue richieste. stringa, solo in Italiano, ad esempio Italiano, Inglese, Francese ecc )\n",
    "                        education (titolo di studio richiesto. stringa, solo in Italiano. Possibili valori (solo uno): {\", \".join(education_levels)}),\n",
    "                        certifications (certificazioni richieste. stringa, ad esempio CISSP, EIPASS, ECDL, Patente B)',\n",
    "\n",
    "                        'Rispondi in formato JSON, senza testo extra, attieniti a questo esempio: \n",
    "                        {{\"turno_preferenza\": \"Pomeriggio, Notte\" ,\n",
    "                        \"parttime_preferenza_perc\": \"30%\",\n",
    "                        \"skills\": \"Python, SQL\",\n",
    "                        \"languages\": \"Italiano, Inglese\",\n",
    "                        \"education\": \"Diploma scuola superiore,\n",
    "                        \"certifications\": \"CISSP, EIPASS, ECDL\"}}. ',\n",
    "\n",
    "                        'Testo: ', {concat_text}\n",
    "                    )\n",
    "                ) AS ner_json\n",
    "            FROM \n",
    "            (SELECT \n",
    "                joborderid, dateadded, \n",
    "                jobtitle, \n",
    "                citta as location, \n",
    "                salary as salary_low, \n",
    "                data_inizio_validita as date_available, \n",
    "                COALESCE(CAST(part_time_percent AS STRING), '') as parttime_preferenza_perc,\n",
    "                COALESCE(skill_list, '') as skills,\n",
    "                COALESCE(titoli_richiesti, '') as education,\n",
    "                COALESCE(DESCRIZIONE_USO_INTERNO, '') as DESCRIZIONE_USO_INTERNO, \n",
    "                COALESCE(TESTO_PUBBLICAZIONE, '') as TESTO_PUBBLICAZIONE, \n",
    "                COALESCE(RICHIESTE_AGGIUNTIVE, '') as RICHIESTE_AGGIUNTIVE, \n",
    "                COALESCE(REQUISITI, '') as REQUISITI\n",
    "            FROM {database}.{schema}.JOBORDER_CLEANED\n",
    "            WHERE CAST(joborderid AS STRING) IN ('829043', '861263', '938151')--LIMIT 100\n",
    "            )\n",
    "            \"\"\"\n",
    "        \n",
    "        \"\"\" \n",
    "                joborderid, date_added, \n",
    "                jobtitle, \n",
    "                citta as location, \n",
    "                salary as salary_low, \n",
    "                data_inizio_validita as date_available, \n",
    "                CONCAT({\"| \".join(open_texts)}) as turno_preferenza,\n",
    "                CONCAT(CAST(part_time_percent AS STRING), '| ', {\"| \".join(open_texts)}) as parttime_preferenza_perc,\n",
    "                CONCAT(skill_list, '| ', {\"| \".join(open_texts)}) as skills,\n",
    "                CONCAT({\"| \".join(open_texts)}) as languages,\n",
    "                CONCAT(titoli_richiesti, '| ', {\"| \".join(open_texts)}) as education,\n",
    "                CONCAT({\"| \".join(open_texts)}) as certifications\n",
    "        \"\"\"\n",
    "        \n",
    "        df = session.sql(query)\n",
    "\n",
    "        df = self.validate_json(df)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def write_table(self, df, table_name = 'output_table'):\n",
    "        \"\"\"\n",
    "        Writes table\n",
    "        Function returns nothing\n",
    "        \"\"\"\n",
    "        df.write.save_as_table(table_name, mode=\"overwrite\")\n",
    "        logger.info(f\"Table {table_name} successfully written\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "68d69f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-13 15:50:55,877: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2026-01-13 15:50:55,881: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2026-01-13 15:50:55,999: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2026-01-13 15:50:56,002: INFO: common: created directory at: artifacts]\n",
      "[2026-01-13 15:50:56,005: INFO: common: created directory at: artifacts/llm]\n",
      "[\"'Skills richieste: ', skills \", \"'Percentuale part time: ', parttime_preferenza_perc \", \"'Titoli di studio richiesti: ', education \", \"'DESCRIZIONE USO INTERNO: ', DESCRIZIONE_USO_INTERNO \", \"'TESTO PUBBLICAZIONE: ', TESTO_PUBBLICAZIONE \", \"'RICHIESTE AGGIUNTIVE: ', RICHIESTE_AGGIUNTIVE \", \"'REQUISITI: ', REQUISITI \"]\n",
      "CONCAT( 'Skills richieste: ', skills , '| ', 'Percentuale part time: ', parttime_preferenza_perc , '| ', 'Titoli di studio richiesti: ', education , '| ', 'DESCRIZIONE USO INTERNO: ', DESCRIZIONE_USO_INTERNO , '| ', 'TESTO PUBBLICAZIONE: ', TESTO_PUBBLICAZIONE , '| ', 'RICHIESTE AGGIUNTIVE: ', RICHIESTE_AGGIUNTIVE , '| ', 'REQUISITI: ', REQUISITI   )\n",
      "[2026-01-13 15:51:48,482: INFO: 2577209802: Table VACANCY_TEST successfully written]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    llm_config = config.get_llm_config()\n",
    "    llm = LLM(config=llm_config)\n",
    "\n",
    "    df = llm.create_prompt_vacancy(session)\n",
    "    #df = response.to_pandas()\n",
    "    llm.write_table(df, 'VACANCY_TEST')\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    raise e\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "96bfd88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "|\"JOBORDERID\"  |\"REQUISITI\"                                         |\n",
      "---------------------------------------------------------------------\n",
      "|861263        |- Diploma di Istituto Tecnico (preferibilmente ...  |\n",
      "|              | - Esperienza anche breve o stage nel settore m...  |\n",
      "|              |- Passione per il settore automotive e buona co...  |\n",
      "|              |- Precisione, attenzione ai dettagli e buona ma...  |\n",
      "|              |- Capacità di lavorare in team e orientamento a...  |\n",
      "|              |                                                    |\n",
      "|829043        |ingegneria, project manager                         |\n",
      "|938151        |Patentino per la conduzione del carrello elevat...  |\n",
      "|              |Esperienza nell’utilizzo del carrello retrattile    |\n",
      "|              |Disponibilità a lavorare su 3 turni compreso we...  |\n",
      "|              |Patente B                                           |\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None) # show all rows \n",
    "pd.set_option(\"display.max_colwidth\", None) # show full column content \n",
    "\n",
    "df[[\"JOBORDERID\", \"REQUISITI\"]].show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d978930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\")\n",
    "pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "23315bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    position = \"Magazziniere\"\n",
    "\n",
    "    df1 = session.sql(f\"\"\" \n",
    "                    select candidateid, age,  location, province_ext, last_job, second_last_job, third_last_job, skills\n",
    "                    from IT_DISCOVERY.CONSUMER_INT_MODEL.MPG_IT_AUTOMATCH_CANDIDATE_FEATURES_NEW\n",
    "                    where latitude is not null and longitude is not null\n",
    "                    and province_ext = 'Milano'\n",
    "                    --AND age < 40\n",
    "                    AND skills ILIKE '%cliente%'\n",
    "                    AND (\n",
    "                    LAST_JOB ILIKE '%{position}%'\n",
    "                    OR SECOND_LAST_JOB ILIKE '%{position}%'\n",
    "                    OR THIRD_LAST_JOB ILIKE '%{position}%' \n",
    "                    )\n",
    "                    \"\"\").collect()\n",
    "    df1\n",
    "\n",
    "    position = \"Magazziniere\"\n",
    "    df2 = session.sql(f\"\"\" \n",
    "                    select candidateid, skills, languages, certifications --age,  location, province_ext, last_job, second_last_job, third_last_job, skills\n",
    "                    from IT_DISCOVERY.CONSUMER_INT_MODEL.MPG_IT_AUTOMATCH_CANDIDATE_FEATURES_NEW\n",
    "                    where latitude is not null and longitude is not null\n",
    "                    and province_ext = 'Milano'\n",
    "                    --AND age < 40\n",
    "                    AND skills ILIKE '%muletto%'\n",
    "                    --AND certifications ILIKE '%patent%'\n",
    "                    --AND languages ILIKE '%tedesco%'\n",
    "                    AND (\n",
    "                    LAST_JOB ILIKE '%{position}%'\n",
    "                    OR SECOND_LAST_JOB ILIKE '%{position}%'\n",
    "                    OR THIRD_LAST_JOB ILIKE '%{position}%' \n",
    "                    )\n",
    "                    \"\"\").collect()\n",
    "    df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
